# Jogo da Velha - IA com Algoritmo GenÃ©tico

Sistema de InteligÃªncia Artificial que usa **Aprendizagem por ReforÃ§o** com **Algoritmo GenÃ©tico** para treinar uma **Rede Neural** a jogar o Jogo da Velha.

## ğŸ“‹ DescriÃ§Ã£o do Projeto

Este projeto implementa uma soluÃ§Ã£o completa de IA onde:
- Uma **Rede Neural MLP** de 2 camadas aprende a jogar o Jogo da Velha
- O **Algoritmo GenÃ©tico** evolui os pesos da rede (sem backpropagation)
- O **Minimax** atua como professor, com dois nÃ­veis de dificuldade:
  - **MÃ©dio**: 50% jogadas minimax, 50% aleatÃ³rias
  - **DifÃ­cil**: 100% jogadas minimax
- Interface grÃ¡fica completa para jogar e treinar

## ğŸ—ï¸ Arquitetura

### Rede Neural (MLP)
- **Entrada**: 9 neurÃ´nios (tabuleiro 3x3)
- **Camada Oculta**: 18 neurÃ´nios (ativaÃ§Ã£o tanh)
- **SaÃ­da**: 9 neurÃ´nios (uma para cada posiÃ§Ã£o)
- Apenas propagaÃ§Ã£o forward (sem backpropagation)

### Algoritmo GenÃ©tico
- **Cromossomos**: Pesos da rede neural (valores reais)
- **SeleÃ§Ã£o**: Elitismo + Torneio
- **Cruzamento**: AritmÃ©tico (para valores reais)
- **MutaÃ§Ã£o**: Gaussiana
- **FunÃ§Ã£o de AptidÃ£o**: Baseada em vitÃ³rias, empates, derrotas e jogadas invÃ¡lidas

### Minimax
- ImplementaÃ§Ã£o clÃ¡ssica do algoritmo
- Modos: MÃ©dio (50% aleatÃ³rio) e DifÃ­cil (100% minimax)
- Usado para treinar a rede neural

## ğŸš€ InstalaÃ§Ã£o

### Requisitos
```bash
Python 3.7+
numpy
matplotlib
tkinter (geralmente jÃ¡ vem com Python)
```

### Instalando DependÃªncias
```bash
pip install numpy matplotlib
```

## ğŸ’» Como Usar

### 1. Interface GrÃ¡fica (Recomendado)
```bash
python main.py --mode gui
```

Na interface vocÃª pode:
- **Jogar contra o Minimax**
- **Treinar a Rede Neural**
- **Jogar contra a Rede Neural treinada**
- **Testar a acurÃ¡cia da rede**

### 2. Treinar via Linha de Comando
```bash
# Treinamento bÃ¡sico
python main.py --mode train

# Treinamento customizado
python main.py --mode train --population 50 --generations 100 --mutation 0.15 --test
```

ParÃ¢metros:
- `--population`: Tamanho da populaÃ§Ã£o (padrÃ£o: 30)
- `--generations`: NÃºmero mÃ¡ximo de geraÃ§Ãµes (padrÃ£o: 50)
- `--mutation`: Taxa de mutaÃ§Ã£o (padrÃ£o: 0.1)
- `--test`: Testa a acurÃ¡cia apÃ³s o treinamento

### 3. Jogar via Linha de Comando
```bash
# Jogar contra Minimax
python main.py --mode play --opponent minimax

# Jogar contra Rede Neural treinada
python main.py --mode play --opponent nn
```

### 4. Testar AcurÃ¡cia
```bash
python main.py --mode test
```

### 5. Visualizar EvoluÃ§Ã£o do Treinamento
```bash
python visualize_training.py
```

Gera grÃ¡ficos mostrando:
- EvoluÃ§Ã£o do fitness (melhor, mÃ©dio, pior)
- Diversidade da populaÃ§Ã£o
- Salva em `training_evolution.png`

## ğŸ“Š Estrutura do Projeto

```
T2_IA/
â”œâ”€â”€ neural_network.py      # ImplementaÃ§Ã£o da Rede Neural MLP
â”œâ”€â”€ genetic_algorithm.py   # Algoritmo GenÃ©tico
â”œâ”€â”€ tic_tac_toe.py        # LÃ³gica do Jogo da Velha
â”œâ”€â”€ minimax.py            # Algoritmo Minimax
â”œâ”€â”€ trainer.py            # Sistema de Treinamento
â”œâ”€â”€ gui.py                # Interface GrÃ¡fica
â”œâ”€â”€ main.py               # Script Principal
â”œâ”€â”€ visualize_training.py # VisualizaÃ§Ã£o da EvoluÃ§Ã£o
â”œâ”€â”€ README.md             # Este arquivo
â””â”€â”€ best_weights.npy      # Pesos treinados (gerado apÃ³s treino)
```

## ğŸ® Modos de Jogo

### 1. Humano vs Minimax
- VocÃª joga como X (sempre comeÃ§a)
- Minimax joga como O
- Perfeito para entender o jogo

### 2. Treinar Rede Neural
- Configure: tamanho da populaÃ§Ã£o, geraÃ§Ãµes, mutaÃ§Ã£o
- Acompanhe a evoluÃ§Ã£o em tempo real
- Agenda de dificuldade:
  - Primeira metade: Minimax MÃ©dio
  - Segunda metade: Minimax DifÃ­cil

### 3. Humano vs Rede Neural
- Teste a rede treinada
- VocÃª joga como X
- Rede Neural joga como O

## ğŸ“ˆ FunÃ§Ã£o de AptidÃ£o

A funÃ§Ã£o de aptidÃ£o avalia cada rede baseando-se em:

```
Fitness = (Î£ resultados dos jogos) / nÃºmero de jogos

Onde cada jogo contribui:
- VitÃ³ria: +100 pontos
- Empate: +50 pontos
- Derrota: -50 pontos
- Jogada invÃ¡lida: -20 pontos
- Jogada vÃ¡lida: +2 pontos
```

## ğŸ”§ ParÃ¢metros Recomendados

### Treinamento RÃ¡pido (Teste)
```python
populaÃ§Ã£o = 20
geraÃ§Ãµes = 30
mutaÃ§Ã£o = 0.15
```

### Treinamento Balanceado (Recomendado)
```python
populaÃ§Ã£o = 30
geraÃ§Ãµes = 50
mutaÃ§Ã£o = 0.1
```

### Treinamento Intensivo (Melhor Resultado)
```python
populaÃ§Ã£o = 50
geraÃ§Ãµes = 100
mutaÃ§Ã£o = 0.08
```

## ğŸ“ EstratÃ©gia de Treinamento

1. **Fase 1 (0 - 50% das geraÃ§Ãµes)**: Minimax MÃ©dio
   - Permite Ã  rede aprender padrÃµes bÃ¡sicos
   - Maior diversidade de situaÃ§Ãµes

2. **Fase 2 (50% - 100% das geraÃ§Ãµes)**: Minimax DifÃ­cil
   - Refinamento das estratÃ©gias
   - Aprende a jogar otimamente

## ğŸ¯ Resultados Esperados

ApÃ³s treinamento adequado, a rede neural deve:
- **AcurÃ¡cia contra Minimax DifÃ­cil**: 0-10% vitÃ³rias, 60-90% empates
- **Jogadas invÃ¡lidas**: < 5%
- **ConvergÃªncia**: 30-50 geraÃ§Ãµes

> **Nota**: Empate contra Minimax perfeito Ã© considerado excelente!

## ğŸ› Troubleshooting

### Erro: "numpy not found"
```bash
pip install numpy
```

### Erro: "tkinter not found"
```bash
# Ubuntu/Debian
sudo apt-get install python3-tk

# Fedora
sudo dnf install python3-tkinter

# macOS (geralmente jÃ¡ incluÃ­do)
```

### Rede nÃ£o aprende bem
- Aumente o tamanho da populaÃ§Ã£o
- Aumente o nÃºmero de geraÃ§Ãµes
- Ajuste a taxa de mutaÃ§Ã£o (0.08 - 0.15)
- Verifique se a agenda de dificuldade estÃ¡ adequada

## ğŸ”¬ Experimentos Sugeridos

1. **Variar topologia da rede**: Teste diferentes tamanhos de camada oculta
2. **Operadores genÃ©ticos**: Teste diferentes cruzamentos e mutaÃ§Ãµes
3. **FunÃ§Ã£o de aptidÃ£o**: Ajuste os pesos das penalizaÃ§Ãµes/bonificaÃ§Ãµes
4. **Agenda de dificuldade**: Teste diferentes progressÃµes

## ğŸ“š Conceitos Implementados

- âœ… Rede Neural MLP (2 camadas)
- âœ… PropagaÃ§Ã£o Forward
- âœ… Algoritmo GenÃ©tico
- âœ… Operadores para valores reais
- âœ… Elitismo
- âœ… SeleÃ§Ã£o por Torneio
- âœ… Cruzamento AritmÃ©tico
- âœ… MutaÃ§Ã£o Gaussiana
- âœ… Minimax (MÃ©dio e DifÃ­cil)
- âœ… Aprendizagem por ReforÃ§o
- âœ… FunÃ§Ã£o de AptidÃ£o customizada
- âœ… CritÃ©rios de parada (geraÃ§Ãµes e convergÃªncia)
- âœ… Interface GrÃ¡fica
- âœ… VisualizaÃ§Ã£o da evoluÃ§Ã£o

## ğŸ‘¨â€ğŸ’» Autor

Projeto desenvolvido para a disciplina de InteligÃªncia Artificial.

## ğŸ“„ LicenÃ§a

Este projeto Ã© de cÃ³digo aberto para fins educacionais.
